import torch
import cv2
import time
import os
import numpy as np
import spidev  # SPI í†µì‹  ëª¨ë“ˆ
from aod_net import AODNet, prune_model, remove_pruning

# === AODNet ëª¨ë¸ ë¡œë“œ ===
aod_model = AODNet().cuda()
checkpoint = torch.load("dehazer.pth")
new_checkpoint = {"aod_block." + k: v for k, v in checkpoint.items()}
aod_model.load_state_dict(new_checkpoint)
aod_model.eval()

prune_model(aod_model, amount=0.3)
remove_pruning(aod_model)

# === YOLOv5 ëª¨ë¸ ë¡œë“œ ===
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', device='cuda:0', force_reload=True)

# === GStreamer ì¹´ë©”ë¼ íŒŒì´í”„ë¼ì¸ ì„¤ì • ===
gst_pipeline = (
    "nvarguscamerasrc ! "
    "video/x-raw(memory:NVMM), width=640, height=480, format=NV12, framerate=10/1 ! "
    "nvvidconv flip-method=2 ! "
    "video/x-raw, format=BGRx ! "
    "videoconvert ! "
    "video/x-raw, format=BGR ! appsink drop=1"
)

# === SPI ì´ˆê¸°í™” ===
spi = spidev.SpiDev()
spi.open(0, 0)
spi.max_speed_hz = 1000000
spi.mode = 0b00

# === SPI í†µì‹  í•¨ìˆ˜ ===
def send_jetson_signals(human, red_light, car):
    tx_byte = (int(human) << 2) | (int(red_light) << 1) | int(car)
    rx_data = spi.xfer2([tx_byte])
    print(f"[Jetson] TX: {bin(tx_byte)} | RX: {rx_data}")

# === ë””í—¤ì´ì§• í•¨ìˆ˜ ===
def dehaze_frame(frame):
    img = torch.from_numpy(frame).float().permute(2,0,1).unsqueeze(0).cuda() / 255.0
    with torch.no_grad():
        output = aod_model(img)
    out_img = output.squeeze().permute(1,2,0).cpu().numpy()
    out_img = (np.clip(out_img, 0 , 1)*255).astype('uint8')
    return cv2.cvtColor(out_img, cv2.COLOR_RGB2BGR)

# === ë³€ìˆ˜ ì´ˆê¸°ê°’ ===
prev_human = prev_red = prev_car = -1  # -1ë¡œ ì„¤ì •í•˜ì—¬ ì²˜ìŒì—ëŠ” ë¬´ì¡°ê±´ SPI ì†¡ì‹ 
cap = cv2.VideoCapture(gst_pipeline, cv2.CAP_GSTREAMER)

if not cap.isOpened():
    print("âš ï¸ Failed to open CSI camera")
    exit()

print("ğŸ“¸ CSI camera opened. Starting YOLOv5 inference...")

try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ Frame read failed.")
            break

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        dehazed = dehaze_frame(rgb)
        results = model(dehazed, size=640)
        predictions = results.pred[0]

        # === ê°ì²´ ì¸ì‹ ê²°ê³¼ì—ì„œ í´ë˜ìŠ¤ íŒë‹¨ ===
        detected_classes = [int(cls) for *box, conf, cls in predictions]

        # YOLOv5 í´ë˜ìŠ¤ ì´ë¦„ ê¸°ë°˜ íŒë³„
        human = 0
        red_light = 0
        car = 0

        for *box, conf, cls in predictions:
            cls_id = int(cls)
            label = model.names[cls_id]
            if label == 'person':
                human = 1
            elif label in ['car', 'truck', 'bus']:
                car = 1
            elif label == 'traffic light':
                # ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
                x1, y1, x2, y2 = map(int, box)
                traffic_crop = dehazed[y1:y2, x1:x2]

                if traffic_crop.size == 0:
                    continue

                hsv = cv2.cvtColor(traffic_crop, cv2.COLOR_BGR2HSV)

                # ë¹¨ê°„ìƒ‰ HSV ë²”ìœ„
                lower_red1 = np.array([0, 100, 100])
                upper_red1 = np.array([10, 255, 255])
                lower_red2 = np.array([160, 100, 100])
                upper_red2 = np.array([179, 255, 255])

                mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
                mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
                red_mask = cv2.bitwise_or(mask1, mask2)

                red_ratio = cv2.countNonZero(red_mask) / (red_mask.shape[0] * red_mask.shape[1])

                if red_ratio > 0.1:
                    red_light = 1
                    print("red light detected")

        # === ê°’ì´ ë°”ë€Œì—ˆì„ ê²½ìš° SPI í†µì‹  ===
        if (human, red_light, car) != (prev_human, prev_red, prev_car):
            send_jetson_signals(human, red_light, car)
            prev_human, prev_red, prev_car = human, red_light, car

        # ê²°ê³¼ í™”ë©´ ì¶œë ¥
        rendered = results.render()[0]
        cv2.imshow("YOLOv5 CSI Preview", rendered)

        key = cv2.waitKey(1) & 0xFF
        if key == 27 or key == ord('q'):
            break

except KeyboardInterrupt:
    print("ğŸ›‘ Interrupted by user.")

finally:
    cap.release()
    cv2.destroyAllWindows()
    spi.close()
    print("âœ… Camera and SPI released.")

